{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Star Calibration for KCWI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "This routine can be used as an alternative to KCWI pipeline **stage 8** if the standard star contains a lot of features.  \n",
    "https://github.com/Keck-DataReductionPipelines/KcwiDRP  \n",
    "  \n",
    "  \n",
    "There are two steps:\n",
    "1. Create a master standard star fit. The default is a polynomial fit without masking. But an spline option is also available in case the polynomial fit doesn't work if the features get complicated. An interactive plot of the data and the fit will be displayed.  \n",
    "      First run with default setting and without masking to pick the ranges of wavelengths to ignore using the interactive plots. Make sure the fit looks good before proceed to the next step.\n",
    "2. Do calibration based on the inverse sensitivity from the standard star fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparation\n",
    "Packages:\n",
    "1. Install plotly with  \n",
    "``conda install -c plotly plotly=4.9.0``  \n",
    "2. And for saving plots  \n",
    "``conda install -c plotly plotly-orca``\n",
    "3. Also make sure you have these  \n",
    "``conda install \"notebook>=5.3\" \"ipywidgets>=7.2\"``\n",
    "\n",
    "\n",
    "Required files:\n",
    "1. Standard star from stage 7 (icubed & dcubed), e.g. kb190101_00011_icubed.fits, kb190101_00011_dcubed.fits\n",
    "2. Standard star sample, this can be found in the pipeline data directory, e.g. feige15.fits  \n",
    "https://github.com/Keck-DataReductionPipelines/KcwiDRP/tree/master/data\n",
    "3. The intensity, variance and mask cubes for objects to be calibrated from stage 7. e.g. *icubed.fits, *vcubed.fits, mcubed.fits\n",
    "4. **Palomar extinction coefficients, this can be found in the kcwi_tools repository, just put it in the working directory.\n",
    "\n",
    "Optional file:\n",
    "- (Spline) To pick out the good points and ignore the features, wavelengths of points to be used for interpolation needs to be put in a column in dat/txt. An example points file for feige15 is in this repository.\n",
    "- (Polynomial) In order to mask out the features in the polynomial standard star fitting, a mask file is needed to indicate the starting and ending points of the masked wavelengths. An example mask file for feige15 can be found in the same respository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions\n",
    "1. Make standard star: ``make_st(st_icube,st_file,*poly=True,*maskd=False,*deg=7,*mask=msk_file)``\n",
    "2. Calibration: ``stage8std(obj_icubed,i_f)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return\n",
    "1. Step 1 returns two structured arrays containing the fits for inverse sensitivity and effective area and automatically save the plots of the fits.\n",
    "2. Step 2 returns the calibrated datacubes as \\*icubes, \\*vcubes, and \\*mcubes in the same directory as the input \\*icubed file of the object."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Theoretical\n",
    "![](https://github.com/wenmeng-ning/kcwi_tools/blob/master/standard_star_fit/Efficiency.png?raw=true)\n",
    "img source: Matuszewski M., Martin D.C., et al., The Keck Cosmic Web Imager Integral Field Spectrograph, doi:10.3847/1538-4357/aad597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import shutil\n",
    "from astropy.modeling import models, fitting\n",
    "import warnings\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import interpolate\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:\n",
    "#   Make Master Standard Star \n",
    "# ----------------------------------------------------------------------------------------\n",
    "# This function performs fits for the inverse sensitivity and effective area using the \n",
    "# standard star sample available and the standard star exposure under the same setting \n",
    "# as the objects to be calibrated. The default is polynomial fit without making, but a\n",
    "# spline fit is also available to use if the features get complicated.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Call:\n",
    "#    i_f, e_f = make_st(st_icube,st_file,*poly=True,*maskd=False,*deg=7,*mask=msk_file)\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Inputs:\n",
    "#   Required:\n",
    "#      st_icube:   (str) path to standard star icube, e.g. '/data/kb190101_00011_icubed.fits'\n",
    "#       st_file:   (str) path to standard star sample, e.g. '/data/feige15.fits'\n",
    "#   Optional:\n",
    "#          poly:  (bool) True/False, whether to use polynomial fit, default is True\n",
    "#          mskd:  (bool) True/False, input mask file if True, default is False\n",
    "#           deg:   (int) degree of the polynomial fit, default deg = 7\n",
    "#     mask_file:   (str) path to mask file (required if poly==False or mskd==True)\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Outputs:\n",
    "#          plots:  inverse sensitivity and effective area, saved to the working directory\n",
    "#         models:  fits for inverse sensitivity and effective area\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Notes:\n",
    "#  1. Make sure both *icubed.fits and *dcubed.fits are there.\n",
    "#  2. There are two ways to tweak the polynomial fit: Mask features and Change degree \n",
    "#     of polynomial fit.\n",
    "#  3. The bluer end of the polynomial fit is tied with the data, but still need to tweak \n",
    "#     and make sure the redder end doesn not blow up.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Reference:\n",
    "#  1. KCWI Data Reduction Pipeline\n",
    "#      https://github.com/Keck-DataReductionPipelines/KcwiDRP\n",
    "#  2. Morrissey P., Matuszewski M., Martin D.C., et al., THE KECK COSMIC WEB\n",
    "#     IMAGER INTEGRAL FIELD SPECTROGRAPH, doi:10.3847/1538-4357/aad597\n",
    "#      https://arxiv.org/pdf/1807.10356.pdf\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Updates: \n",
    "#    Sep  7, 2020  W.Ning  Updated documentation.\n",
    "#    Sep  6, 2020  W.Ning  Fixed issue in stardard star position.\n",
    "#    Aug 29, 2020  W.Ning  Added spline fit. Updated documentation.\n",
    "#    Aug 26, 2020  W.Ning  Created.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "def make_st(icube,st_file,poly=True,maskd=False,deg=7,**kwargs):\n",
    "    icube_f = icube.replace(\"icubed\",\"icubes\")\n",
    "    dcube = icube.replace('icubed','dcubed')\n",
    "    shutil.copy2(icube,icube_f)\n",
    "    \n",
    "    mask = kwargs['mask']\n",
    "    \n",
    "    st_hdr = fits.getheader(icube)\n",
    "    st_data = fits.getdata(icube)\n",
    "    \n",
    "    # Get information\n",
    "    expt = st_hdr['XPOSURE'] # Exposure time\n",
    "    air = st_hdr['AIRMASS'] # Airmass\n",
    "    w0 = st_hdr['CRVAL3'] # Wavelength Zeropoint\n",
    "    dw = st_hdr['CD3_3'] # Angstroms per pixel\n",
    "    ws = w0 + np.shape(st_data)[0]*dw # wavelength endpoint\n",
    "    crpix = st_hdr['CRPIX3'] # Wavelength reference pixel\n",
    "    wl = np.maximum(st_hdr['WAVGOOD0'],3500); wr = st_hdr['WAVGOOD1'] # Good wavelength range to work with\n",
    "    wa0 = st_hdr['WAVALL0']; wa1 = st_hdr['WAVALL1'] # All wavelength range\n",
    "    pad_y = st_hdr['DARPADY'] # DAR padding in y\n",
    "    area = int(760000) # Keck II Effective area in cm^2\n",
    "    gw = [int((wl-w0)/dw+10),int((wr-w0)/dw-10)] # Good wavelength pixel range\n",
    "    gy = [pad_y, np.shape(st_data)[1]-pad_y] # Good y range\n",
    "    wav = w0+(np.arange(np.shape(st_data)[0])+1)*dw \n",
    "    gwav_st = wav[gw[0]:gw[1]]\n",
    "\n",
    "    # Find standard star\n",
    "    sum_dat = np.sum(st_data[gw[0]:gw[1],gy[0]:gy[1],:],0)\n",
    "    xmax = np.argmax(np.std(sum_dat,0))\n",
    "    ymax = np.argmax(sum_dat[:,xmax])+gy[0]\n",
    "\n",
    "    # Read Keck Extinction data\n",
    "    atm_data = fits.getdata('snfext.fits')\n",
    "\n",
    "    # Extinction curve\n",
    "    ext = np.interp(wav,atm_data.LAMBDA,atm_data.EXT)\n",
    "    ext_flx = 10**(ext*air*0.4)\n",
    "    \n",
    "    with fits.open(icube_f, mode='update') as hdu:\n",
    "        data = hdu[0].data\n",
    "        for i in np.arange(np.shape(data)[0]):\n",
    "            data[i,:,:] = data[i,:,:]*ext_flx[i]\n",
    "        hdr = hdu[0].header\n",
    "        hdr.append(('EXTCOR', 'T', ' Extinction corrected'), end=True)\n",
    "        hdr.append(('AVEXCOR',np.mean(ext_flx),' Average extin. correction (flux ratio)'),end=True)\n",
    "    hdu.close()\n",
    "    \n",
    "    st_corr = fits.getdata(icube_f)\n",
    "    origspec = np.sum(np.sum(st_data[gw[0]:gw[1],ymax-30:ymax+30,xmax-3:xmax+3],1),1)/expt\n",
    "    corrspec = np.sum(np.sum(st_corr[gw[0]:gw[1],ymax-30:ymax+30,xmax-3:xmax+3],1),1)/expt\n",
    "    \n",
    "    dcub = fits.getdata(dcube)[gw[0]:gw[1],ymax,xmax]\n",
    "    \n",
    "    # Standard Star sample\n",
    "    st_profile = fits.getdata(st_file)\n",
    "    stp_ind = np.logical_and(wl<st_profile.WAVELENGTH,st_profile.WAVELENGTH<wr)\n",
    "    stp_l = st_profile.WAVELENGTH[stp_ind]\n",
    "    stp_flx = st_profile.FLUX[stp_ind]\n",
    "    stp_fwhm = np.max(st_profile.FWHM[stp_ind])\n",
    "        \n",
    "    # Inverse Sensitivity\n",
    "    stp = np.interp(gwav_st,stp_l,stp_flx)\n",
    "    invsen = stp / corrspec\n",
    "        \n",
    "    # Effective area\n",
    "    st_pho = 5.03411250e07*stp*gwav_st*dw # convert to photons/s/cm^2/(wl bin = dw)\n",
    "    earea = origspec/st_pho*dw / dcub\n",
    "        \n",
    "    # Fit with tied blue end\n",
    "    p_init = models.Legendre1D(degree=deg); p_init.c0.fixed=True\n",
    "    fit_p = fitting.LevMarLSQFitter()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        finvsen = fit_p(p_init,gwav_st-gwav_st[0],invsen-invsen[0])\n",
    "    finvsen.c0.value = invsen[0]\n",
    "    a_init = models.Legendre1D(degree=deg); a_init.c0.fixed=True\n",
    "    fit_a = fitting.LevMarLSQFitter()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        fearea = fit_a(a_init,gwav_st-gwav_st[0],earea-earea[0])\n",
    "    fearea.c0.value = earea[0]\n",
    "        \n",
    "    figtitle = 'Inverse Sensitivity and Effective Area - Poly'\n",
    "    \n",
    "    mod = 'poly'\n",
    "    \n",
    "    if maskd==True:\n",
    "        # Mask\n",
    "        msk = open(mask, \"r\")\n",
    "        msk_data = msk.readlines()\n",
    "        mskd = np.zeros((np.shape(msk_data)[0],2))\n",
    "        for i in np.arange(np.shape(msk_data)[0]):\n",
    "            mskd[i,0] = int(msk_data[i].split()[0])\n",
    "            mskd[i,1] = int(msk_data[i].split()[1])\n",
    "        gwav_ind=[0]*np.shape(gwav_st)[0];\n",
    "        for i in np.arange(np.shape(msk_data)[0]):\n",
    "            gwav_ind = np.add(gwav_ind, [int(np.logical_and(e>mskd[i][0],e<mskd[i][1])) for e in gwav_st])\n",
    "        gwav = [gwav_st[int(ind)] for ind in np.argwhere(gwav_ind==0)]\n",
    "        \n",
    "        corrspec_m = [corrspec[int(ind)] for ind in np.argwhere(gwav_ind==0)]\n",
    "        origspec_m = [origspec[int(ind)] for ind in np.argwhere(gwav_ind==0)]\n",
    "        \n",
    "        corrspec_c = np.interp(gwav_st,gwav,corrspec_m)\n",
    "        origspec_c = np.interp(gwav_st,gwav,origspec_m)\n",
    "        \n",
    "        # Inverse Sensitivity\n",
    "        stp = np.interp(gwav_st,stp_l,stp_flx)\n",
    "        invsen_m = stp / corrspec_c\n",
    "        \n",
    "        # Effective area\n",
    "        st_pho_m = 5.03411250e7*stp*gwav_st*dw # convert to photons/s/cm^2/(wl bin = dw)\n",
    "        earea_m = origspec_c/st_pho_m*dw / dcub\n",
    "        \n",
    "        figtitle = 'Inverse Sensitivity and Effective Area - Masked Poly'\n",
    "        \n",
    "        # Fit with tied blue end\n",
    "        p_init = models.Legendre1D(degree=deg); p_init.c0.value = 0; p_init.c0.fixed=True\n",
    "        fit_p = fitting.LevMarLSQFitter()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            finvsen = fit_p(p_init,gwav_st-gwav_st[0],invsen_m-invsen[0])\n",
    "            finvsen.c0.value = invsen[0]\n",
    "        a_init = models.Legendre1D(degree=deg); a_init.c0.value = 0; a_init.c0.fixed=True\n",
    "        fit_a = fitting.LevMarLSQFitter()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            fearea = fit_a(a_init,gwav_st-gwav_st[0],earea_m-earea[0])\n",
    "        fearea.c0.value = earea[0]\n",
    "        \n",
    "    if poly==False:\n",
    "        # Good points to use\n",
    "        msk = open(mask, \"r\")\n",
    "        points = msk.readlines()\n",
    "        pts = [int(i.split()[0]) for i in points]\n",
    "        gwav_ind=[0]*np.shape(gwav_st)[0];\n",
    "        for i in pts:\n",
    "            gwav_ind = np.add(gwav_ind, [int(i==e) for e in gwav_st])\n",
    "        corrspec_m = [corrspec[int(ind)] for ind in np.argwhere(gwav_ind==1)]\n",
    "        origspec_m = [origspec[int(ind)] for ind in np.argwhere(gwav_ind==1)]\n",
    "        \n",
    "        corrspec_c = np.interp(gwav_st,pts,corrspec_m)\n",
    "        origspec_c = np.interp(gwav_st,pts,origspec_m)\n",
    "        \n",
    "        # Inverse Sensitivity\n",
    "        stp = np.interp(gwav_st,stp_l,stp_flx)\n",
    "        invsen_m = stp / corrspec_c\n",
    "        \n",
    "        # Effective area\n",
    "        st_pho_m = 5.03411250e7*stp*gwav_st*dw # convert to photons/s/cm^2/(wl bin = dw)\n",
    "        earea_m = origspec_c/st_pho_m*dw / dcub\n",
    "            \n",
    "        # Fit\n",
    "        finvsen = interpolate.InterpolatedUnivariateSpline(gwav_st,invsen_m)\n",
    "        fearea = interpolate.InterpolatedUnivariateSpline(gwav_st,earea_m)\n",
    "        \n",
    "        figtitle = 'Inverse Sensitivity and Effective Area - Spline'\n",
    "        mod = 'spline'\n",
    "    \n",
    "    \n",
    "    # Plotting\n",
    "    f = make_subplots(rows=2, cols=1,shared_xaxes=True,vertical_spacing=0.01)\n",
    "    f.add_trace(go.Scatter(x=gwav_st,y=invsen,name='InvData'),row=1,col=1)\n",
    "    f.add_trace(go.Scatter(x=gwav_st,y=earea,name='EffAreaData'),row=2,col=1)\n",
    "    if poly == True:\n",
    "        f.add_trace(go.Scatter(x=gwav_st,y=finvsen(gwav_st-gwav_st[0]),name='InvFit'),row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=gwav_st,y=fearea(gwav_st-gwav_st[0]),name='EffAreaeFit'),row=2,col=1)\n",
    "    else:\n",
    "        f.add_trace(go.Scatter(x=gwav_st,y=finvsen(gwav_st),name='InvFit'),row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=gwav_st,y=fearea(gwav_st),name='EffAreaFit'),row=2,col=1)\n",
    "    f.update_layout(height=800,width=800,title=figtitle)\n",
    "    f.show()\n",
    "    f.write_image(figtitle+'.png')\n",
    "    \n",
    "    \n",
    "    invsen_fit = np.recarray((1,),dtype=[('wav','O'),('invsen','O'),('model','O'),('fit','O')])\n",
    "    effarea_fit = np.recarray((1,),dtype=[('wav','O'),('earea','O'),('model','O'),('fit','O')])\n",
    "    \n",
    "    invsen_fit.wav[0] = gwav_st; effarea_fit.wav[0] = gwav_st; \n",
    "    invsen_fit.invsen[0] = invsen; effarea_fit.earea[0] = earea;\n",
    "    invsen_fit.fit[0] = finvsen; effarea_fit.fit[0] = fearea;\n",
    "    invsen_fit.model[0] = mod; effarea_fit.model[0] = mod;\n",
    "    \n",
    "    return invsen_fit,effarea_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Poly Example\n",
    "i_f,e_f = make_st('kb190101_00011_icubed.fits','feige15.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Masked Poly Example\n",
    "i_f,e_f = make_st('kb190101_00011_icubed.fits','feige15.fits',deg=6,maskd=True,mask='mask.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Spline Example\n",
    "i_f,e_f = make_st('kb190101_00011_icubed.fits','feige15.fits',poly=False,mask='points.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2:\n",
    "#   Calibration for object\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# This function performs flux calibration for the object with results from step 1.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Call:\n",
    "#    stage8std(obj_icub,i_f)\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Inputs:\n",
    "#      obj_icub:   (str) path to object intensity cube, e.g. '/data/kb190101_00011_icubed.fits'\n",
    "#           i_f:   (arr) structured array containing the inverse sentivity fit from step 1\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Outputs:\n",
    "#     datacubes:  calibrated datacubes (*icubes,*vcubes,*mcubes)\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Notes:\n",
    "#  1. Put variance and mask datacubes in the same directory as the intensity cubes\n",
    "#  2. The data beyond the good range is set to zero.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# Updates: \n",
    "#    Aug 29, 2020   W.Ning  Updated\n",
    "#    Aug 26, 2020   W.Ning  Created\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "def stage8std(obj,i_f):\n",
    "    vfil = obj.replace('icubed','vcubed'); mfil = obj.replace('icubed','mcubed')\n",
    "    var_f = obj.replace('icubed','vcubes'); msk_f = obj.replace('icubed','mcubes')\n",
    "    obj_f = obj.replace('icubed','icubes')\n",
    "    hdr = fits.getheader(obj); st_data = fits.getdata(obj);\n",
    "    shutil.copy2(obj,obj_f); shutil.copy2(vfil,var_f); shutil.copy2(mfil,msk_f)\n",
    "    \n",
    "    # Get Information\n",
    "    expt = hdr['XPOSURE']\n",
    "    air = hdr['AIRMASS']\n",
    "    w0 = hdr['CRVAL3']; dw = hdr['CD3_3']\n",
    "    wav = w0+(np.arange(np.shape(st_data)[0]))*dw \n",
    "    wl = np.maximum(hdr['WAVGOOD0'],3500); wr = hdr['WAVGOOD1']\n",
    "    gw = [int((wl-w0)/dw+10),int((wr-w0)/dw-10)]\n",
    "    \n",
    "    # Extinction Correction\n",
    "    if i_f.model[0]=='poly':\n",
    "        st = i_f.fit[0](wav-i_f.wav[0][0])\n",
    "    if i_f.model[0]=='spline':\n",
    "        st = i_f.fit[0](wav)\n",
    "    \n",
    "    # Read Keck Extinction data\n",
    "    atm_data = fits.getdata('snfext.fits')\n",
    "\n",
    "    # Extinction curve\n",
    "    ext = np.interp(wav,atm_data.LAMBDA,atm_data.EXT)\n",
    "    ext_flx = 10**(ext*air*0.4)\n",
    "    \n",
    "    st = st*ext_flx\n",
    "    \n",
    "    with fits.open(obj_f, mode='update') as hdu:\n",
    "        data = hdu[0].data\n",
    "        for i in np.arange(np.shape(data)[0]):\n",
    "            if np.logical_and(i>gw[0],i<gw[1]):\n",
    "                data[i,:,:] = (data[i,:,:]/expt)*st[i]*1e16\n",
    "            else:\n",
    "                data[i,:,:] = 0\n",
    "    hdu.close()\n",
    "    \n",
    "    with fits.open(var_f, mode='update') as hdu:\n",
    "        data = hdu[0].data\n",
    "        for i in np.arange(np.shape(data)[0]):\n",
    "            if np.logical_and(i>gw[0],i<gw[1]):\n",
    "                data[i,:,:] = data[i,:,:]*(st[i]*1e16/expt)**2\n",
    "            else:\n",
    "                data[i,:,:] = 0\n",
    "    hdu.close()\n",
    "     \n",
    "    for file in [obj_f,var_f,msk_f]:\n",
    "        with fits.open(file, mode='update') as hdu:\n",
    "            hdr = hdu[0].header\n",
    "            hdr.append(('EXTCOR', 'T', ' Extinction corrected'), end=True)\n",
    "            hdr.append(('AVEXCOR',np.mean(ext_flx),' Average extin. correction (flux ratio)'),end=True)\n",
    "            hdr.append(('STDCOR','T',' Std corrected?'), end=True)\n",
    "            hdr.append(('BUNIT','FLAM16**2',' brightness units (Flam*10^16)^2'), end=True)\n",
    "        hdu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage8std('kb190101_00021_icubed.fits',i_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
